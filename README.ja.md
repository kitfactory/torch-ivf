# torch-ivfï¼ˆæ—¥æœ¬èªï¼‰

**Faiss ãƒ©ã‚¤ã‚¯ã«ä½¿ãˆã‚‹ã€PyTorch ãƒã‚¤ãƒ†ã‚£ãƒ– IVFã€‚**  
CPU / CUDA / ROCm / DirectML ã‚’ **åŒä¸€ã‚³ãƒ¼ãƒ‰**ã§æ‰±ãˆã‚‹ã“ã¨ã‚’ç›®æ¨™ã«ã—ã¦ã„ã¾ã™ï¼ˆç‰¹ã« Windows + ROCm ã‚’é‡è¦–ï¼‰ã€‚

- ğŸ” **Faiss é¡ä¼¼ã®APIã§ç§»è¡ŒãŒç°¡å˜**ï¼ˆ`IndexFlatL2` / `IndexFlatIP`, `IndexIVFFlat` ç›¸å½“ã® APIï¼‰
- ğŸ“ˆ **throughput é ˜åŸŸã§ faiss-cpu ã‚’æœ€å¤§ 5.20x**ï¼ˆ`nq=19600` ã§ 50,709 / 9,758 â‰’ 5.20xï¼‰
- ğŸ§© **PyTorch ã® backend ãŒå‹•ã‘ã°åŒã˜ã‚³ãƒ¼ãƒ‰ã§å‹•ã**ï¼ˆCPU/CUDA/ROCm/DirectMLã€‚*One codebase across backends*ï¼‰
- ğŸ§ª **å®Ÿæ¸¬ãƒ»å†ç¾æ‰‹é †ã‚ã‚Š**ï¼ˆenv/jsonl + scripts åŒæ¢±ã€‚*Reproducible benchmarks included*ï¼‰

> English README: `README.md`

---

## ğŸ“Œ 1åˆ†ã§ã‚ã‹ã‚‹ï¼šFaiss ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘

Faiss ã® API ã¨ã®å¯¾æ¯”ã¯ä¸‹è¨˜ã§ã™ã€‚ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚‚ã”å‚ç…§ãã ã•ã„ï¼ˆ[`docs/tutorial.ja.md`](docs/tutorial.ja.md)ï¼‰ã€‚

```python
from torch_ivf.index import IndexFlatL2, IndexFlatIP, IndexIVFFlat
```

| ã‚„ã‚ŠãŸã„ã“ã¨ | Faiss | torch-ivf |
|---|---|---|
| å…¨æ¢ç´¢ï¼ˆL2/IPï¼‰ | `faiss.IndexFlatL2 / faiss.IndexFlatIP` | `torch_ivf.index.IndexFlatL2 / torch_ivf.index.IndexFlatIP` |
| IVFï¼ˆL2/IPï¼‰ | `faiss.IndexIVFFlat` | `torch_ivf.index.IndexIVFFlat` |
| é€Ÿåº¦ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | `nprobe` ç­‰ | `nprobe` + `search_mode` + `max_codes` |

**GPU æ¨å¥¨è¨­å®š**ï¼š`search_mode="auto"`ï¼ˆtiny-batch ã¯è»½ã„çµŒè·¯ã€throughput ã¯ `csr`ï¼‰  
åˆ‡ã‚Šæ›¿ãˆåŸºæº–: `avg_group_size = (nq * nprobe) / nlist`ã€`avg_group_size >= auto_search_avg_group_threshold * (nlist / 512)` ãªã‚‰ `csr`ï¼ˆCUDA ã®ã¿ï¼‰ã€‚

---

## ã©ã†ã„ã£ãŸé ˜åŸŸã§é€Ÿã„ã‹ï¼Ÿï¼ˆ1æšã¾ã¨ã‚ï¼‰

- **throughputï¼ˆä¾‹: `nq >= 512`ï¼‰ã€€å¾—æ„**  
  `search_mode=csr` ãŒåŠ¹ãã‚„ã™ãã€**faiss-cpu ã‚’è¤‡æ•°å€ä¸Šå›ã‚‹**ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã™ã€‚
- **tiny-batchï¼ˆä¾‹: `nq <= 32`ï¼‰ä¸å¾—æ„**  
  ã‚«ãƒ¼ãƒãƒ«èµ·å‹•ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒæ”¯é…çš„ã«ãªã‚Šã‚„ã™ãã€CPU ã‚„ `search_mode=matrix` ãŒå‹ã¤ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
- **æ¨å¥¨è¨­å®š**  
  GPU ã§ã¯ `search_mode="auto"` ã‚’æ—¢å®šã«ã—ã€**å¯èƒ½ãªã‚‰ã‚¯ã‚¨ãƒªã‚’ã¾ã¨ã‚ã¦æŠ•ã’ã¦ãã ã•ã„**ï¼ˆauto ã¯ tiny-batch ã§ã¯è»½ã„çµŒè·¯ã€throughput ã§ã¯ `csr` ã‚’é¸ã¶ï¼‰ã€‚

---

## ğŸ“Š å®Ÿæ¸¬ï¼ˆä»£è¡¨å€¤ï¼‰

> ãƒ™ãƒ³ãƒæ¡ä»¶ä¾‹: `nb=262144, train_n=20480, nlist=512, nprobe=32, k=20, float32, --warmup 1 --repeat 5`  
> å®Ÿè¡Œç’°å¢ƒ: AMD64 Family 26 Model 112 Stepping 0, AuthenticAMD / Windows 11 / PyTorch ROCm 7.1.52802-561cc400e1  
> æ›´æ–°æ—¥æ™‚: `2025-12-24T18:08:10`ï¼ˆ`scripts/benchmark_sweep_nq.py`ã€`search_ms` ã¯ medianï¼‰
>
> â€»ã“ã®è¡¨ã¯ **`search_mode=auto` å›ºå®š**ã§ã™ï¼ˆauto ã¯ tiny-batch ã§ã¯è»½ã„çµŒè·¯ã€throughput ã§ã¯ `csr` ã‚’é¸æŠï¼‰ã€‚æœ€å¤§ throughput ã‚’è¦‹ãŸã„å ´åˆã¯ `search_mode=csr` ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
> faiss-cpu ã¯æ—¢å®šã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®šï¼ˆç’°å¢ƒä¾å­˜ï¼‰ã§ã™ã€‚å†ç¾ã™ã‚‹å ´åˆã¯ `OMP_NUM_THREADS` ã‚’å›ºå®šã—ã¦ãã ã•ã„ï¼ˆä¾‹: Linux/macOS `export OMP_NUM_THREADS=16` / Windows `set OMP_NUM_THREADS=16`ï¼‰ã€‚

| nq | torch-ivfï¼ˆROCm GPU, autoï¼‰ | faiss-cpuï¼ˆCPUï¼‰ |
|---:|---:|---:|
| 512 | **20,017 QPS** | 6,271 QPS |
| 2,048 | **36,344 QPS** | 10,000 QPS |
| 19,600 | **50,709 QPS** | 9,758 QPS |

**é€Ÿåº¦å„ªå…ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä»»æ„ãƒ»recallä½ä¸‹ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰**  
ã“ã‚Œã‚‰ã®æ¡ä»¶ã§QPSã‚’è¨˜è¼‰ã™ã‚‹å ´åˆã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚ä½µè¨˜ã—ã¦ãã ã•ã„ã€‚
- `max_codes`ï¼ˆä¾‹: `32768`ï¼‰ã§å€™è£œæ•°ã®ä¸Šé™ã‚’è¨­å®šã™ã‚‹ã€‚
- `SearchParams(profile="approx", candidate_budget=32768, budget_strategy="distance_weighted", list_ordering="residual_norm_asc")`ï¼ˆL2ã®ã¿ï¼‰ã€‚



### è¿‘ä¼¼ãƒ—ãƒªã‚»ãƒƒãƒˆï¼ˆper-list äºˆç®—ï¼‰

`SearchParams.profile` ã¯ per-list äºˆç®—ã¤ãã®è¿‘ä¼¼ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚

- `approx_fast`: `candidate_budget=32768`, `use_per_list_sizes=True`
- `approx_balanced`: `candidate_budget=65536`, `use_per_list_sizes=True`
- `approx_quality`: `candidate_budget=131072`, `use_per_list_sizes=True`ï¼ˆä¸‹ã®ãƒ™ãƒ³ãƒã§ recall~0.995ï¼‰

ä¾‹:

```python
from torch_ivf.index import SearchParams

params = SearchParams(profile="approx_quality")
scores, ids = index.search(xq, k=20, params=params)

# æ˜ç¤ºçš„ã«ä¸Šæ›¸ãã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™:
params = SearchParams(profile="approx_quality", candidate_budget=98304)
```

### ãƒ—ãƒªã‚»ãƒƒãƒˆã®æ¸¬å®šçµæœï¼ˆper-list, csrï¼‰

> ä¸Šã®è¡¨ã¨åŒã˜ç’°å¢ƒã€‚`seed=1234`, `search_mode=csr`ã€‚

| candidate_budget | QPS | recall@kï¼ˆunlimited æ¯”ï¼‰ |
|---:|---:|---:|
| 32,768 | 54.9k | 0.930242 |
| 65,536 | 51.9k | 0.976895 |
| 98,304 | 53.8k | 0.990066 |
| 131,072 | 50.8k | 0.995046 |

æ³¨: 98,304ï¼ˆç´„96kï¼‰ã¯ recall~0.99 ã¾ã§åˆ°é”ã—ã¾ã™ãŒã€0.995 ã®ã‚²ãƒ¼ãƒˆã¯æº€ãŸã—ã¾ã›ã‚“ã€‚


### ã‚°ãƒ©ãƒ•ï¼šQPS vs nqï¼ˆtiny-batch â†’ throughputï¼‰

èµ¤: torch-ivfï¼ˆROCm GPU, autoï¼‰ / é»’: faiss-cpuï¼ˆCPUï¼‰

![QPS vs nq](docs/assets/qps_vs_nq.svg)

---

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆPyTorch ã¯å‰æï¼‰

torch-ivf ã¯ PyTorch ã‚’ **å¼·åˆ¶ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã›ã‚“**ã€‚  
CUDA/ROCm/DirectML/CPU ãªã©ã€åˆ©ç”¨ç’°å¢ƒã«åˆã£ãŸ PyTorch ã‚’ **å…ˆã«**å…¥ã‚Œã¦ã‹ã‚‰ torch-ivf ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚

- ã™ã§ã« PyTorch ã‚’å…¥ã‚Œã¦ã„ã‚‹å ´åˆï¼ˆæ¨å¥¨ï¼‰:
  ```bash
  pip install torch-ivf
  ```
- CPU ã§æ‰‹æ—©ãè©¦ã—ãŸã„å ´åˆï¼ˆPyTorch ã‚‚ pip ã§å…¥ã‚Œã‚‹ï¼‰:
  ```bash
  pip install "torch-ivf[pytorch]"
  ```

---

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### æœ€å°ã‚³ãƒ¼ãƒ‰ï¼ˆè‡ªåˆ†ã®ã‚³ãƒ¼ãƒ‰ã«åŸ‹ã‚è¾¼ã‚€ï¼‰

```python
import torch
from torch_ivf.index import IndexIVFFlat

d = 128
xb = torch.randn(262144, d, device="cuda", dtype=torch.float32)
xq = torch.randn(2048, d, device="cuda", dtype=torch.float32)

index = IndexIVFFlat(d=d, nlist=512, nprobe=32, metric="l2").to("cuda")
index.search_mode = "auto"
index.train(xb[:20480])
index.add(xb)

dist, ids = index.search(xq, k=20)
print(dist.shape, ids.shape)

# é€Ÿåº¦/è‡ªå·±æ¯”è¼ƒrecallã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼ˆå¿…è¦ãªã¨ãã ã‘ï¼‰
# index.max_codes = 32768
```

1) åˆæˆãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¢ï¼ˆã¾ãšå‹•ä½œç¢ºèªï¼‰:
```bash
python examples/ivf_demo.py --device cpu --verify
python examples/ivf_demo.py --device cuda --verify
```

2) ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼ˆåˆ©ç”¨è€…å‘ã‘ï¼‰:
- [`docs/tutorial.ja.md`](docs/tutorial.ja.md)
- [`docs/tutorial.en.md`](docs/tutorial.en.md)

---

## é‡è¦ãƒã‚¤ãƒ³ãƒˆï¼ˆè»¢é€ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼‰

- ç›®çš„ device ä¸Šã§ãƒ†ãƒ³ã‚½ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆ`torch.randn(..., device=device)`ï¼‰
- `add` / `search` ã¯ã§ãã‚‹ã ã‘ **å¤§ãã„ãƒãƒƒãƒ**ã§å‘¼ã¶ï¼ˆæ•°åƒã€œï¼‰
- `index = IndexIVFFlat(...).to(device)` ã¯ 1 å›ã ã‘ã€‚å†…éƒ¨ãƒãƒƒãƒ•ã‚¡ã¯åŒã˜ device ã«å¸¸é§ã•ã›ã‚‹
- DataLoader çµŒç”±ãªã‚‰ `pin_memory=True` ã¨ `tensor.to(device, non_blocking=True)` ã‚’ä½¿ã†

---

## ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰

- [`scripts/benchmark.py`](scripts/benchmark.py): torch-ivf ãƒ™ãƒ³ãƒï¼ˆCPU/ROCmï¼‰ã€‚JSON ã‚’å‡ºåŠ›ã— [`benchmarks/benchmarks.jsonl`](benchmarks/benchmarks.jsonl) ã«è¿½è¨˜
- [`scripts/benchmark_faiss_cpu.py`](scripts/benchmark_faiss_cpu.py): faiss-cpu å‚ç…§ãƒ™ãƒ³ãƒ
- [`scripts/benchmark_sweep_nq.py`](scripts/benchmark_sweep_nq.py): `nq` ã‚¹ã‚¤ãƒ¼ãƒ—ï¼ˆtiny-batch vs throughput ã®å¢ƒç•Œï¼‰
- [`scripts/benchmark_sweep_max_codes.py`](scripts/benchmark_sweep_max_codes.py): `max_codes` ã‚¹ã‚¤ãƒ¼ãƒ—ï¼ˆé€Ÿåº¦/è‡ªå·±æ¯”è¼ƒ recallï¼‰
- [`scripts/benchmark_sweep_candidate_budget.py`](scripts/benchmark_sweep_candidate_budget.py): `candidate_budget` ?????approx ???/recall?
- [`scripts/dump_env.py`](scripts/dump_env.py): [`benchmarks/env.json`](benchmarks/env.json) ã‚’ç”Ÿæˆ
- [`scripts/profile_ivf_search.py`](scripts/profile_ivf_search.py): `IndexIVFFlat.search` ã® `torch.profiler` è¡¨ã‚’è¡¨ç¤º

---

## æœ€å°ã®å†ç¾æ‰‹é †ï¼ˆãŠã™ã™ã‚ï¼‰

README ã®ã‚°ãƒ©ãƒ•/è¡¨ã‚’å†ç¾ã™ã‚‹æœ€çŸ­æ‰‹é †ã§ã™ã€‚

```bash
uv run python scripts/dump_env.py
uv run python scripts/benchmark_sweep_nq.py --torch-device cuda --torch-search-mode auto
uv run python scripts/benchmark_sweep_max_codes.py --torch-device cuda --torch-search-mode csr
```

çµæœã¯ [`benchmarks/benchmarks.jsonl`](benchmarks/benchmarks.jsonl) ã«è¿½è¨˜ã•ã‚Œã¾ã™ã€‚æœ€æ–°ãƒ¬ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦ README ã®ä»£è¡¨å€¤ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚

---

## ãªãœé€Ÿã„ï¼Ÿï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’â€œæ§‹é€ â€ã§æ½°ã™ï¼‰

torch-ivf ã¯ã€ãŸã è·é›¢è¨ˆç®—ã‚’é€Ÿãã™ã‚‹ã ã‘ã§ã¯ãªãã€IVF ã§æ”¯é…çš„ã«ãªã‚Šã‚„ã™ã„ **(A) å€™è£œå‚ç…§ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹** ã¨ **(B) å·¨å¤§ãªé¸åˆ¥ï¼ˆtopkï¼‰** ã‚’ã€ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¨æ¢ç´¢æ‰‹é †ã®è¨­è¨ˆã§æ½°ã™æ–¹é‡ã§ã™ã€‚

### 1) ã¾ãšã€Œã©ã“ãŒé…ã„ã‹ã€ã‚’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã§ç¢ºå®š

å½“ã¦ãšã£ã½ã†ã®é«˜é€ŸåŒ–ã‚’é¿ã‘ã‚‹ãŸã‚ã€`torch.profiler` ã§ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã‚’ç¢ºèªã—ã¾ã™ã€‚

- ä½¿ã†ã‚‚ã®: [`scripts/profile_ivf_search.py`](scripts/profile_ivf_search.py)
- ç™ºè¦‹ã—ãŸã“ã¨:
  - `matrix` å´: `aten::index_select` / `aten::gather` / å¤§ãã„ `aten::topk` ãŒæ”¯é…ã—ã‚„ã™ã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚
  - `csr` å´: â€œãƒ©ãƒ³ãƒ€ãƒ å‚ç…§ï¼ˆgather ç³»ï¼‰â€ ã®æ¯”ç‡ãŒä¸‹ãŒã‚Šã€`slice` + GEMM ãŒä¸»ä½“ã«ãªã‚Šã‚„ã™ã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚

### 2) gather â†’ sliceï¼ˆlist ã‚’é€£ç¶šé…ç½®ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ¶ˆã™ï¼‰

GPU ã«ã¨ã£ã¦å³ã—ã„ã®ã¯ã€å€™è£œãƒ™ã‚¯ãƒˆãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒã€Œé£›ã³é£›ã³ã€ã«ãªã‚‹ã“ã¨ã§ã™ï¼ˆ`gather/index_select` ãŒå¤šã„ï¼‰ã€‚

torch-ivf ã¯ `add` ã®æ®µéšã§ã€inverted list ã”ã¨ã« **ãƒ™ã‚¯ãƒˆãƒ«ã‚’é€£ç¶šé…ç½®**ã—ã€æ¤œç´¢æ™‚ã¯ `slice` ã§å€™è£œã‚’å–ã‚Œã‚‹å½¢ã«ã—ã¾ã—ãŸã€‚

- æ¦‚å¿µçš„ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ:
  - `packed_embeddings`: list å˜ä½ã«ä¸¦ã³æ›¿ãˆãŸãƒ™ã‚¯ãƒˆãƒ«ï¼ˆé€£ç¶šï¼‰
  - `list_offsets[l]:list_offsets[l+1]`: list `l` ã® `[start:end)` ç¯„å›²
  - `list_ids`: packed ã®è¡Œ â†’ å…ƒID ã®å¯¾å¿œ

ã“ã‚Œã«ã‚ˆã‚Šå€™è£œã®å–ã‚Šå‡ºã—ãŒ

- ä»¥å‰: `index_select/gather`ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰
- ã„ã¾: `packed_embeddings[start:end]`ï¼ˆé€£ç¶š `slice`ï¼‰

ã¨ãªã‚Šã€ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã®æ€§è³ªãŒæ”¹å–„ã—ã¾ã—ãŸã€‚

### 3) å·¨å¤§ topk â†’ local topk + mergeï¼ˆé¸åˆ¥ã‚’å°ã•ãã—ã¦å›æ•°ã‚’æœ€é©åŒ–ï¼‰

`matrix` ãƒ‘ã‚¹ã¯ã€Œå€™è£œã‚’å›ºå®šå½¢çŠ¶ã®è¡Œåˆ—ã«è©°ã‚ã¦ã€1 å›ã®å¤§ãã„ `topk`ã€ã«ãªã‚Šã‚„ã™ãã€å€™è£œæ•°ãŒè†¨ã‚‰ã‚€ã¨ `topk` ã¨ä¸­é–“ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ¡ãƒ¢ãƒªç§»å‹•ãŒæ”¯é…çš„ã«ãªã‚Šã¾ã™ã€‚

`csr` ãƒ‘ã‚¹ã¯ list å˜ä½ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã—ãŸ:

1. list ã®å€™è£œ `X` ã‚’ `slice` ã§å–å¾—
2. `Q @ X.T` ã§è·é›¢ï¼ˆã‚¹ã‚³ã‚¢ï¼‰ã‚’ä½œã‚‹
3. list å†…ã§ `local_topk(k)`
4. `merge` ã§å…¨ä½“ top-k ã‚’æ›´æ–°ï¼ˆonline / bufferedï¼‰

ã“ã®å½¢ã«ã™ã‚‹ã¨ã€å¸¸ã«ã€Œå°ã•ã„ topkã€ã‚’å›ã›ã‚‹ãŸã‚ã€throughput é ˜åŸŸã§ä¼¸ã³ã‚„ã™ããªã‚Šã¾ã—ãŸã€‚

### 4) GEMM å½¢ã«å¯„ã›ã‚‹ï¼ˆãƒ™ãƒ³ãƒ€ãƒ¼ BLAS ã‚’æœ€å¤§é™ä½¿ã†ï¼‰

è·é›¢è¨ˆç®—ã¯å¯èƒ½ãªé™ã‚Šè¡Œåˆ—ç©ï¼ˆGEMMï¼‰ã«å¯„ã›ã¾ã™ã€‚

- IP: `scores = Q @ X.T`
- L2: `||q-x||^2 = ||q||^2 + ||x||^2 - 2 (Q @ X.T)`

ROCm/CUDA ã® BLASï¼ˆrocBLAS/cuBLASï¼‰ã‚’æ´»ã‹ã—ã‚„ã™ã„å½¢ãªã®ã§ã€GPU ã§ã® throughput ãŒå‡ºã‚„ã™ããªã‚Šã¾ã—ãŸã€‚

### 5) å‡¦ç†ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆæ¤œç´¢ã®æµã‚Œï¼‰

```mermaid
flowchart TD
  Q["Query Q: nq x d"] --> Coarse["Coarse: centroid topk (nprobe)"]
  Coarse --> Lists["Probed list ids: nq x nprobe"]
  Lists --> Tasks["Tasks: query_id, list_id"]
  Tasks --> Group["Group by list_id"]
  Group --> Slice["Slice packed_embeddings by list_offsets"]
  Slice --> GEMM["Scores/Dist via GEMM: Q @ X.T"]
  GEMM --> LocalTopk["local topk k per list"]
  LocalTopk --> Merge["merge to global top-k"]
  Merge --> Out["Distances/Ids: nq x k"]
```

---

## é–‹ç™ºï¼ˆuvï¼‰

```bash
uv sync
uv run pytest
```

---

## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [`docs/concept.md`](docs/concept.md) â€“ èƒŒæ™¯ã¨ç‹™ã„
- [`docs/spec.md`](docs/spec.md) â€“ ä»•æ§˜ï¼ˆAPI/æŒ™å‹•ï¼‰
- [`docs/plan.md`](docs/plan.md) â€“ é€²æ—ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [`docs/tutorial.ja.md`](docs/tutorial.ja.md) â€“ ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼ˆæ—¥æœ¬èªï¼‰
- [`docs/tutorial.en.md`](docs/tutorial.en.md) â€“ Tutorial (English)

